
1. NOT WORK---[Integrating ORB-SLAM3 with ROS2 Humble on Raspberry Pi 5: A Step-by-Step Guide](https://medium.com/@antonioconsiglio/integrating-orb-slam3-with-ros2-humble-on-raspberry-pi-5-a-step-by-step-guide-78e7b911c361) USD5 per month
2. [In-depth description of ORB-SLAM3](https://medium.com/@parkie0517/orb-slam-%EA%B3%B5%EB%B6%80-457dfc8c31db) 
3. https://blog.csdn.net/m0_58173801/article/details/127068794
4. Didnt work. Building Opencv failed. https://gist.github.com/bharath5673/4295e666cbe654a83226a2549a972c4f
5. https://github.com/Cobular/ORB_SLAM3_ROS2_Iron
6. https://github.com/UZ-SLAMLab/ORB_SLAM3
7. https://wenku.csdn.net/answer/mybw0dgz1k?ydreferer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8%3D



1. Test SpectacularAi example from [here](https://github.com/SpectacularAI/sdk-examples/tree/main/python/oak/ros2)
	1. NOTE: pip install spectacularAI does not work for arm. I sent mail to try and get holdof it but no reply yet






# NOT WORK---Installation Process from Medium (NOTE: specific versions are important): 

1. Install Eigen v 3.4.0 and OpenCV v4.5.4
```Shell
sudo apt install libeigen3-dev
pip install opencv-python==4.5.4.60
sudo apt install ros-humble-cv-bridge -y
```

2. Install Pangolin v0.6
```Shell
git clone https://github.com/stevenlovegrove/Pangolin Pangolin
cd Pangolin  
./scripts/install_prerequisites.sh recommended
```
Add the following line (if not there already) in the file /home/nico/Pangolin/include/pangolin/gl/colour.h`:
```Shell
#include <limits>  
```
then do:
```Shell
cd
cd Pangolin
git checkout v0.6  
mkdir build  
cd build  
cmake .. && make  
sudo make install
```

3. Installing ORB-SLAM3 Library
```Shell
git clone -b c++14_comp https://github.com/UZ-SLAMLab/ORB_SLAM3.git ORB_SLAM3
```
Change the build.sh file to look as follows(limit the number of CPU cores used during the compilation process(-j4 = using 4 cores; maybe use 6 on VIM4)):
```Shell
echo "Configuring and building Thirdparty/DBoW2 ..."  
  
cd Thirdparty/DBoW2  
mkdir build  
cd build  
cmake .. -DCMAKE_BUILD_TYPE=Release  
make -j4  
  
cd ../../g2o  
  
echo "Configuring and building Thirdparty/g2o ..."  
  
mkdir build  
cd build  
cmake .. -DCMAKE_BUILD_TYPE=Release  
make -j4  
  
cd ../../Sophus  
  
echo "Configuring and building Thirdparty/Sophus ..."  
  
mkdir build  
cd build  
cmake .. -DCMAKE_BUILD_TYPE=Release  
make -j4  
  
cd ../../../  
  
echo "Uncompress vocabulary ..."  
  
cd Vocabulary  
tar -xf ORBvoc.txt.tar.gz  
cd ..  
  
echo "Configuring and building ORB_SLAM3 ..."  
  
mkdir build  
cd build  
cmake .. -DCMAKE_BUILD_TYPE=Release  
make -j2
```
Now run the installation and add orb-slam3 libraries to .bashrc:
```Shell
cd ORB_SLAM3
./build.sh
```
I got an error and had to do the following:
- Open the file: /home/nico/ORB_SLAM3/Examples/RGB-D-Inertial/rgbd_inertial_realsense_D435i.cc
- Locate instances of `std::chrono::monotonic_clock` and replace them with `std::chrono::steady_clock`
```Shell
cd ORB_SLAM3
./build.sh
```

```Shell
echo 'export LD_LIBRARY_PATH=/home/nico/ORB_SLAM3/lib:/usr/local/lib:$LD_LIBRARY_PATH' >> ~/.bashrc
```

4. Creating Example Node Using ORB-SLAM3 Library(some steps can be avoided if ros2_ws already exists):
```Shell
mkdir ros2_ws
cd ros2_ws
mkdir src  
cd src  
ros2 pkg create --build-type ament_cmake slam_example
```
	Now go inside the `slam_example` folder and create three new files (the second file was changed from src/image_grabber.hpp to src/image_grabber.cpp - I think guide had a mistake):
```Shell
cd slam_example  
touch include/slam_example/image_grabber.hpp
touch src/image_grabber.cpp
touch src/orb_slam_example.cpp
```
Add following code to its respective file:
	Image_grabber.hpp:
```Shell
#include "/home/nico/ORB_SLAM3/include/System.h"

```

	Image_grabber.cpp:
```Shell
#include "/home/nico/ros2_ws/src/slam_example/include/slam_example/image_grabber.hpp" // Ensure this matches your directory structure
```

	orb_slam_example.cpp
```Shell
#include "/home/nico/ORB_SLAM3/include/System.h"
#include "/home/nico/ros2_ws/src/slam_example/include/slam_example/image_grabber.hpp"
```

5. Now create a `config` folder to store the ORB vocabulary file (a `.txt` file located in the `ORB_SLAM3/Vocabulary` folder) and a configuration file that the SLAM system will use to understand the camera settings and ORB parameters
```Shell
cd 
cd ros2_ws/src/slam_example
mkdir config  
cp /home/nico/ORB_SLAM3/Vocabulary/ORBvoc.txt config/  
touch config/camera_and_slam_settings.yaml
```
Add following code to the /home/nico/ros2_ws/src/slam_example/config/camera_and_slam_settings.yaml file:
```Shell
y
y
y
y
y
y
y
y
```


6. Next, we will create a `launch` folder and a launch file to simplify running the node:
```Shell
cd 
cd ros2_ws/src/slam_example
mkdir launch  
touch launch/slam_example.launch.py
```
Add the following to the /home/nico/ros2_ws/src/slam_example/launch/slam_example.launch.py file:
```Shell
y
y
y
y
y
y
y
```

7. Building the package:
	1. Add the following to the /home/nico/ros2_ws/src/slam_example/CMakeLists.txt file:
```Shell
set(ORB_SLAM3_DIR "/home/nico/ORB_SLAM3")  # Adjust this to your ORB_SLAM3 directory
set(PANGOLIN_LIB_DIR "/home/nico/Pangolin/build/src/libpangolin.so")  # Adjust this to your Pangolin lib path
```

	2. Add the following to the /home/nico/ros2_ws/src/slam_example/package.xml file:
```Shell
y
y
y
y
y
y
y
```

Change:
/home/nico/Pangolin/include/pangolin/pangolin.h and rebuild
```Shell
#include </home/nico/Pangolin/include/pangolin/platform.h>
```
/home/nico/ORB_SLAM3/include/Map.h and rebuild
```Shell
#include </home/nico/Pangolin/include/pangolin/pangolin.h>
```



	3. Build the workspace:
```Shell
cd ~/ros2_ws
colcon build --packages-select slam_example
```
		If you have "stderr" output instead of successful colcon build, try building again
	Add following line to bashrc, if not there already
```Shell
source ~/ros2_ws/install/setup.bash
```

7. Run the node using
```Shell
ros2 launch slam_example slam_example.launch.py
```








# NOT WORK---From Medium:
**Integrating ORB-SLAM3 with ROS2 Humble on Raspberry Pi 5: A Step-by-Step Guide**

If you’ve struggled to install and use ORB-SLAM3 within your ROS2 node for SLAM, this blog post is just what you need. I’ve been through the same challenges, especially with handling the library dependencies like Eigen and Pangolin, which can make the process quite frustrating.
## **Environment Overview**

My setup is based on **Ubuntu 22.04**, with a few key packages already installed. To follow this step-by-step guide seamlessly, make sure you have **Eigen v3.4.0** installed. This specific version will help avoid compatibility issues. You’ll also need **OpenCV** installed; in my case, I’m using **v4.5.4**.

Of course, having **ROS2 Humble** installed is a must. If you haven’t done that yet, you can follow my installation guide here: [How to Install ROS2 Humble on Raspberry Pi 5]().

Once you’ve got ROS2 Humble, Eigen, and OpenCV set up, you’ll need to install the `cv_bridge` package by running:

sudo apt install ros-humble-cv-bridge -y

## Installing Pangolin

Pangolin is a lightweight and highly efficient OpenGL-based library for managing 3D visualization. It’s widely used for visual SLAM (Simultaneous Localization and Mapping) applications like ORB-SLAM3 due to its real-time rendering capabilities.

Let’s start by downloading the Pangolin source code:

git clone https://github.com/stevenlovegrove/Pangolin Pangolin

Next, navigate to the downloaded folder and install the recommended prerequisites:

cd Pangolin  
./scripts/install_prerequisites.sh recommended

After the prerequisites are installed, we need to switch to an older version of Pangolin, specifically **v0.6**, as it is compatible with ORB-SLAM3. Before building the library, you must modify a file for compatibility.

Add the following line in the file `Pangolin/include/pangolin/gl/colour.h`:

// Pangolin/include/pangolin/gl/colour.h  
...  
  
#include <limits>  
  
...

Once that’s done, you can proceed with the build and installation:

git checkout v0.6  
mkdir build  
cd build  
cmake .. && make  
make install

## Installing ORB-SLAM3 Library

**ORB-SLAM3** is a state-of-the-art library for **Simultaneous Localization and Mapping (SLAM)**. It supports monocular, stereo, and RGB-D cameras and is widely used in robotics for real-time 3D mapping and navigation. Its versatility and precision make it a popular choice for SLAM applications in both research and industry.

Let’s begin by downloading the ORB-SLAM3 source code:

git clone -b c++14_comp https://github.com/UZ-SLAMLab/ORB_SLAM3.git ORB_SLAM3

Here, we are downloading the version compatible with the **C++14 compiler**.

Next, I made a small adjustment to the `build.sh` file to limit the number of CPU cores used during the compilation process. This helps avoid system overload, especially when working on devices like the Raspberry Pi. Below is the modified `build.sh` file:

#!/bin/bash  
  
echo "Configuring and building Thirdparty/DBoW2 ..."  
  
cd Thirdparty/DBoW2  
mkdir build  
cd build  
cmake .. -DCMAKE_BUILD_TYPE=Release  
make -j4  
  
cd ../../g2o  
  
echo "Configuring and building Thirdparty/g2o ..."  
  
mkdir build  
cd build  
cmake .. -DCMAKE_BUILD_TYPE=Release  
make -j4  
  
cd ../../Sophus  
  
echo "Configuring and building Thirdparty/Sophus ..."  
  
mkdir build  
cd build  
cmake .. -DCMAKE_BUILD_TYPE=Release  
make -j4  
  
cd ../../../  
  
echo "Uncompress vocabulary ..."  
  
cd Vocabulary  
tar -xf ORBvoc.txt.tar.gz  
cd ..  
  
echo "Configuring and building ORB_SLAM3 ..."  
  
mkdir build  
cd build  
cmake .. -DCMAKE_BUILD_TYPE=Release  
make -j2

After the installation is complete, you’ll need to update your `.bashrc` file to ensure the system can find the ORB-SLAM3 libraries. Run the following command in your terminal:

echo 'export LD_LIBRARY_PATH=<path to ORB_SLAM3/lib>:/usr/local/lib:$LD_LIBRARY_PATH' >> ~/.bashrc

Replace `<path_to_ORB_SLAM3/lib>` with the actual path where you’ve installed ORB-SLAM3.

Now the ORB-SLAM3 installation process is complete!

## Example Node Using ORB-SLAM3 Library

Now, we can create a workspace folder called `examples_ws`:

mkdir examples_ws

Next, we go inside the `examples_ws` folder and create our first ROS2 package called `slam_example`, which will use the ORB-SLAM3 library in its nodes:

cd examples_ws  
mkdir src  
cd src  
ros2 pkg create --build-type ament_cmake slam_example

At this point, we will have the following folder structure:

/project  
│  
├── /ORB_SLAM3            # Contains the ORB_SLAM3 library  
│   ├── build  
│   ├── Thirdparty  
│   ├── Vocabulary  
│   └── ...               
│  
├── /Pangolin             # Contains the Pangolin library  
│   ├── build  
│   ├── include  
│   ├── scripts  
│   └── ...               
│  
└── /examples_ws          # ROS2 workspace  
    ├── /src              # Source folder for ROS2 packages  
        └── /slam_example   
            ├── CMakeLists.txt  
            ├── package.xml  
            ├── /include  # Header files (if any)  
            ├── /launch   # Launch files  
            └── /src      # Source code for nodes

Next, we will go inside the `slam_example` folder and create three new files:

cd slam_example  
nano include/slam_example/image_grabber.hpp  
nano src/image_grabber.hpp  
nano src/orb_slam_example.cpp

In the `image_grabber.hpp` and `image_grabber.cpp` files, we will define the `ImageGrabber` class. This class will handle incoming images from a ROS2 image topic, process them for SLAM, and publish the estimated pose (frame orientation) to a topic as an odometry message.

In `orb_slam_example.cpp`, we will write the code that sets up the ROS2 node, creates the necessary subscribers and publishers, and spins the node.

Let’s begin!

**image_grabber.hpp  
**In this header file, we declare the `ImageGrabber` class:

#ifndef IMAGE_GRABBER_HPP  
#define IMAGE_GRABBER_HPP  
  
#include <rclcpp/rclcpp.hpp>  
#include <sensor_msgs/msg/image.hpp>  
#include <cv_bridge/cv_bridge.h>  
#include <opencv2/opencv.hpp>  
#include <opencv2/imgproc/imgproc.hpp>  
#include <nav_msgs/msg/odometry.hpp>  
  
#include "include/System.h"  // Include the SLAM system header  
  
#include <queue>  
#include <mutex>  
#include <memory>  
  
class ImageGrabber : public std::enable_shared_from_this<ImageGrabber>  
{  
public:  
    ImageGrabber();  
    ImageGrabber(std::shared_ptr<ORB_SLAM3::System> pSLAM, bool bClahe,   
      
    rclcpp::Publisher<nav_msgs::msg::Odometry>::SharedPtr rospub,  
    std::shared_ptr<rclcpp::Node> ros_node,const std::string camera_frame_name);  
  
    void grabImage(const sensor_msgs::msg::Image::SharedPtr msg);  
    cv::Mat getImage(const sensor_msgs::msg::Image::SharedPtr &img_msg);  
    void virtual processImages();  
    void publishSE3fToOdom(const Sophus::SE3f& se3);  
  
    std::queue<sensor_msgs::msg::Image::SharedPtr> img0Buf;  
    std::mutex mBufMutex;  
    std::shared_ptr<ORB_SLAM3::System> mpSLAM;  
    const bool mbClahe;  
    cv::Ptr<cv::CLAHE> mClahe = cv::createCLAHE(3.0, cv::Size(8, 8));  
      
    rclcpp::Publisher<nav_msgs::msg::Odometry>::SharedPtr odom_pub_;  
    nav_msgs::msg::Odometry odom_msg_;  
    std::shared_ptr<rclcpp::Node> rosNode_;  
    const std::string tf_frame;  
};  
  
#endif // IMAGE_GRABBER_HPP

**image_grabber.cpp**

In this file, we define the constructor and methods for the `ImageGrabber` class.

**Class Constructor:**

mageGrabber::ImageGrabber() : mbClahe(false), first_pose(true) {}  
  
ImageGrabber::ImageGrabber(std::shared_ptr<ORB_SLAM3::System> pSLAM, bool bClahe,   
    rclcpp::Publisher<nav_msgs::msg::Odometry>::SharedPtr rospub,  
    std::shared_ptr<rclcpp::Node> ros_node, const std::string camera_frame_name)  
    : mpSLAM(pSLAM), mbClahe(bClahe), first_pose(true),  
    odom_pub_(rospub), rosNode_(ros_node),  
    tf_frame(camera_frame_name)   
    {  
        odom_msg_.header.frame_id = "odom";  
        odom_msg_.child_frame_id = tf_frame;  
  
        odom_msg_.pose.pose.position.x = 0.0;  
        odom_msg_.pose.pose.position.y = 0.0;  
        odom_msg_.pose.pose.position.z = 0.0;  
          
        odom_msg_.pose.pose.orientation.x = 0.0;  
        odom_msg_.pose.pose.orientation.y = 0.0;  
        odom_msg_.pose.pose.orientation.z = 0.0;  
        odom_msg_.pose.pose.orientation.w = 0.0;  
    }  

**Image Handling:**

void ImageGrabber::grabImage(const sensor_msgs::msg::Image::SharedPtr img_msg)  
{  
    std::lock_guard<std::mutex> lock(mBufMutex);  
    if (!img0Buf.empty())  
        img0Buf.pop();  // Remove the oldest image to process the latest one  
    img0Buf.push(img_msg);  
}  
  
cv::Mat ImageGrabber::getImage(const sensor_msgs::msg::Image::SharedPtr &img_msg)  
{  
    // Convert the ROS image message to a cv::Mat object  
    cv_bridge::CvImageConstPtr cv_ptr;  
    try  
    {  
        cv_ptr = cv_bridge::toCvShare(img_msg, sensor_msgs::image_encodings::MONO8);  
    }  
    catch (cv_bridge::Exception& e)  
    {  
        RCLCPP_ERROR(rclcpp::get_logger("ImageGrabber"), "cv_bridge exception: %s", e.what());  
        return cv::Mat();  
    }  
    return cv_ptr->image.clone();  
}

**Image Processing Loop:**

void ImageGrabber::processImages()  
{  
    while (rclcpp::ok())  
    {  
        cv::Mat im;  
        double tIm = 0;  
        // Check if there is any image in the buffer  
        if (!img0Buf.empty())  
        {  
            {  
                std::lock_guard<std::mutex> lock(mBufMutex);  
                im = getImage(img0Buf.front());  
                tIm = img0Buf.front()->header.stamp.sec + img0Buf.front()->header.stamp.nanosec * 1e-9;  
                img0Buf.pop();  
            }  
  
            if (im.empty()) {  
                continue;  
            }  
  
            if (mbClahe) {  
                mClahe->apply(im, im);  // Apply CLAHE if enabled  
            }  
  
            // Process the image in the SLAM system  
            Sophus::SE3f curr_pose;  
            try {  
                curr_pose = mpSLAM->TrackMonocular(im, tIm);  
            } catch (const std::exception &e) {  
                std::cerr << "Exception caught: " << e.what() << std::endl;  
            }  
              
            //publish pose  
            publishSE3fToOdom(curr_pose);             
        }  
  
        std::this_thread::sleep_for(std::chrono::milliseconds(1));  
    }  
}

**Publishing the Estimated Pose:**

void ImageGrabber::publishSE3fToOdom(const Sophus::SE3f& se3) {  
      
    // Extract the translation (position)  
    Eigen::Vector3f translation = se3.translation();  
    odom_msg_.pose.pose.position.x = translation.x();  
    odom_msg_.pose.pose.position.y = translation.y();  
    odom_msg_.pose.pose.position.z = translation.z();  
  
    // Extract the rotation and convert to quaternion  
    Eigen::Matrix3f rotation_matrix = se3.rotationMatrix();  
    Eigen::Quaternionf quaternion(rotation_matrix);  
  
    odom_msg_.pose.pose.orientation.x = quaternion.x();  
    odom_msg_.pose.pose.orientation.y = quaternion.y();  
    odom_msg_.pose.pose.orientation.z = quaternion.z();  
    odom_msg_.pose.pose.orientation.w = quaternion.w();  
  
  
    odom_pub_->publish(odom_msg_);  
}

**orb_slame_example.cpp**

#include <rclcpp/rclcpp.hpp>  
#include <sensor_msgs/msg/image.hpp>  
#include <cv_bridge/cv_bridge.h>  
#include <opencv2/opencv.hpp>  
#include <opencv2/imgproc/imgproc.hpp>  
#include <nav_msgs/msg/odometry.hpp>  
  
#include <rclcpp/qos.hpp>  
#include <rmw/types.h>    
  
#include "include/System.h"  // Include the SLAM system header  
  
#include "rover_slam/image_grabber.hpp"  
  
#include <queue>  
#include <mutex>  
#include <thread>  
  
  
int main(int argc, char *argv[])  
{  
    rclcpp::init(argc, argv);  
  
    auto node = std::make_shared<rclcpp::Node>("example_slam");  
      
    std::string config_path = node->get_parameters("config_path").as_string();  
    std::string vocab_path = node->get_parameters("vocab_path").as_string();  
    bool showPangolin = false ; // true If you want to spone the Pangolin window with pose estimation drawed  
    bool bEqual = false;  
  
    // Publish odom message from SE3  
    auto odom_publ = node->create_publisher<nav_msgs::msg::Odometry>("/odometry/slam", 10);  
      
  
    // Create SLAM system and ImageGrabber  
    auto SLAM = std::make_shared<ORB_SLAM3::System>(vocab_path, config_path, ORB_SLAM3::System::MONOCULAR, showPangolin);  
    auto igb = std::make_shared<ImageGrabber>(SLAM, bEqual,  odom_publ, node, "oak-d_frame");  
  
    // Creating Image subscription  
    std::string imgTopicName = "/rover_camera/image_raw" ;  
    // Subscribe to the camera image topic  
    auto sub_img0 = node->create_subscription<sensor_msgs::msg::Image>(  
        imgTopicName, 5, [igb](const sensor_msgs::msg::Image::SharedPtr msg) { igb->grabImage(msg); });  
  
    // Start processing images in a separate thread  
    std::thread image_thread(&ImageGrabber::processImages, igb);  
  
    // Run the ROS node  
    rclcpp::spin(node);  
    std::cout << "Node stop to spinning!" << std::endl;  
  
    // Shutdown the node and wait for the thread to complete  
    rclcpp::shutdown();  
    image_thread.join();  
  
    return 0;  
}

Before we build and run the node, a few things need to be set up. First, we need to create a `config` folder to store the ORB vocabulary file (a `.txt` file located in the `ORB_SLAM3/Vocabulary` folder) and a configuration file that the SLAM system will use to understand the camera settings and ORB parameters.

// Inside the /slam_example folder  
mkdir config  
cp /project/ORB_SLAM3/Vocabulary/ORBvoc.txt config/  
  
nano config/camera_and_slam_settings.yaml

In the `camera_and_slam_settings.yaml` file, we define the necessary camera parameters and ORB settings for SLAM:

%YAML:1.0  
  
#--------------------------------------------------------------------------------------------  
# Camera Parameters. Adjust them!  
#--------------------------------------------------------------------------------------------  
File.version: "1.0"  
  
Camera.type: "PinHole"  
  
# Right Camera calibration and distortion parameters (OpenCV)  
  
Camera1.fx: 454.58868408203125  
Camera1.fy: 454.58868408203125  
Camera1.cx: 330.0748291015625  
Camera1.cy: 252.9288330078125  
  
# distortion parameters  
Camera1.k1: 0.0  
Camera1.k2: 0.0  
Camera1.p1: 0.0  
Camera1.p2: 0.0  
  
# Camera original resolution  
Camera.width: 640  
Camera.height: 480  
  
#If image is resized  
# Camera.newHeight  
# Camera.newWidth  
  
# Camera frames per second   
Camera.fps: 30  
  
# Color order of the images (0: BGR, 1: RGB. It is ignored if images are grayscale)  
Camera.RGB: 1  
  
#--------------------------------------------------------------------------------------------  
# ORB Parameters  
#--------------------------------------------------------------------------------------------  
# ORB Extractor: Number of features per image  
ORBextractor.nFeatures: 1250  
  
# ORB Extractor: Scale factor between levels in the scale pyramid    
ORBextractor.scaleFactor: 1.2  
  
# ORB Extractor: Number of levels in the scale pyramid   
ORBextractor.nLevels: 8  
  
# ORB Extractor: Fast threshold  
# Image is divided in a grid. At each cell FAST are extracted imposing a minimum response.  
# Firstly we impose iniThFAST. If no corners are detected we impose a lower value minThFAST  
# You can lower these values if your images have low contrast     
ORBextractor.iniThFAST: 20  
ORBextractor.minThFAST: 5  
  
#--------------------------------------------------------------------------------------------  
# Viewer Parameters  
#--------------------------------------------------------------------------------------------  
Viewer.KeyFrameSize: 0.05  
Viewer.KeyFrameLineWidth: 1.0  
Viewer.GraphLineWidth: 0.9  
Viewer.PointSize: 2.0  
Viewer.CameraSize: 0.08  
Viewer.CameraLineWidth: 3.0  
Viewer.ViewpointX: 0.0  
Viewer.ViewpointY: -0.7  
Viewer.ViewpointZ: -3.5  
Viewer.ViewpointF: 500.0

Next, we will create a `launch` folder and a launch file to simplify running the node.

A launch file in ROS2 Humble allows you to easily configure and start nodes with pre-defined parameters, making the setup process more streamlined.

// Inside the /slam_example folder  
mkdir launch  
nano launch/slam_example.launch.py

In the `slam_example.launch.py` file, we define the following:

from launch import LaunchDescription  
from ament_index_python.packages import get_package_share_directory  
from launch_ros.actions import Node  
import os  
  
def generate_launch_description():  
      
    slam_pkg_path= get_package_share_directory("slam_example")  
  
    vocab_file = os.path.join(config_path,"config","ORBvoc.txt")  
    settings_file = os.path.join(config_path,"config","camera_and_slam_settings.yaml")  
  
  
    slam_node = Node(  
            package='slam_example',  
            executable='orb_slam3_example',  
            output='screen',  # Optional: Print output to screen  
            parameters=[  
              {"vocab_path":vocab_file},  
              {"config_path":settings_file}]  
        )  
  
  
    return LaunchDescription([  
        slam_node  
    ])

## Build the Package and Run

Now we’ve arrived at the final part of this guide. We will write the `CMakeLists.txt` and `package.xml` files to build the ROS2 package and run the node.

**CMakeLists.txt**

cmake_minimum_required(VERSION 3.8)  
project(slam_example)  
  
if(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES "Clang")  
  add_compile_options(-Wall -Wextra -Wpedantic)  
endif()  
  
# find dependencies  
find_package(ament_cmake REQUIRED)  
find_package(ament_cmake_python REQUIRED)  
find_package(rclpy REQUIRED)  
find_package(rclcpp REQUIRED)  
find_package(sensor_msgs REQUIRED)  
find_package(nav_msgs REQUIRED)  
  
find_package(Sophus REQUIRED)  
find_package(Pangolin REQUIRED)  
find_package(OpenGL REQUIRED)  
find_package(GLEW REQUIRED)   
  
# Find OpenCV (ORB_SLAM3 depends on OpenCV)  
find_package(OpenCV REQUIRED)  
find_package(cv_bridge REQUIRED)  
find_package(Eigen3 REQUIRED)  
  
set(ORB_SLAM3_DIR "/project/ORB_SLAM3")  # Adjust this to your ORB_SLAM3 directory  
set(PANGOLIN_LIB_DIR "/project/Pangolin/build/src/libpangolin.so")  # Adjust this to your Pangolin lib path  
  
include_directories(include)  
  
include_directories(  
  ${OpenCV_INCLUDE_DIRS}  
  ${cv_bridge_INCLUDE_DIRS}  
  ${EIGEN3_INCLUDE_DIR}  
  ${ORB_SLAM3_DIR}  
  ${ORB_SLAM3_DIR}/include  
  ${ORB_SLAM3_DIR}/include/CameraModels  
  ${ORB_SLAM3_DIR}/Thirdparty/Sophus  
  )  
    
add_executable(orb_slam3_example src/orb_slame_example.cpp src/image_grabber.cpp)  
  
link_directories(  
  ${ORB_SLAM3_DIR})  
  
  
# Link the ORB_SLAM3 library and dependencies  
target_link_libraries(orb_slam3_example  
  ${OpenCV_LIBS}  
  ${cv_bridge_LIBRARIES}  
  ${ORB_SLAM3_DIR}/lib/libORB_SLAM3.so  
  ${OPENGL_LIBRARIES}   
  ${GLEW_LIBRARIES}  # Add this line to link GLEW  
  ${PANGOLIN_LIB_DIR}  
)  
  
  
# Specify ROS 2 package dependencies  
ament_target_dependencies(orb_slam3_example  
  rclcpp  
  sensor_msgs  
  cv_bridge  
  nav_msgs  
)  
  
install(TARGETS  
  orb_slam3_example  
  DESTINATION lib/${PROJECT_NAME}  
)  
  
  
install(  
  DIRECTORY config launch  
  DESTINATION share/${PROJECT_NAME}  
)  
  
  
if(BUILD_TESTING)  
  find_package(ament_lint_auto REQUIRED)  
  set(ament_cmake_copyright_FOUND TRUE)  
  set(ament_cmake_cpplint_FOUND TRUE)  
  ament_lint_auto_find_test_dependencies()  
endif()  
  
ament_package()

**package.xml**

<?xml version="1.0"?>  
<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>  
<package format="3">  
  <name>slam_example</name>  
  <version>0.0.0</version>  
  <description>TODO: Package description</description>  
  <maintainer email=" ... ">aconsiglio</maintainer>  
  <license>TODO: License declaration</license>  
  
  <buildtool_depend>ament_cmake</buildtool_depend>  
  
  <depend>rclcpp</depend>  
  <depend>opencv</depend>  
  <depend>Pangolin</depend>  
  <depend>cv_bridge</depend>  
  <depend>nav_msgs</depend>  
  
  <exec_depend>sensor_msgs</exec_depend>  
  
  <test_depend>ament_lint_auto</test_depend>  
  <test_depend>ament_lint_common</test_depend>  
  
  <export>  
    <build_type>ament_cmake</build_type>  
  </export>  
</package>

## Final Steps

Now that everything is in place, let’s build the package:

// In the workspace folder  
colcon build

Once the build is complete, source the environment and launch the node:

// in the workspace folder  
. install/setup.bash  
ros2 launch slam_example slam_example.launch.py

# **Summary**

In this guide, we’ve walked through the entire process of integrating ORB-SLAM3 with ROS2 Humble on a Raspberry Pi 5, covering everything from installing ROS2 and Pangolin to building the ORB-SLAM3 library.

We also developed a custom ROS2 node to process images for SLAM and publish the odometry output. By following these steps, you now have a functional ROS2 package using ORB-SLAM3, capable of performing real-time SLAM on your Raspberry Pi 5. Happy SLAMming!






