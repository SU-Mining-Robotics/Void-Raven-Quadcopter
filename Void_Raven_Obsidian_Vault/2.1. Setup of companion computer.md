- Mention that localisation, mapping and path planning processing is all done on board

# 1. Ubuntu Mate Raspberry Pi 4B 

## 1.1. Flash Ubuntu Mate to RBPi (Works)

1. flash ubuntu mate onto the sd card using raspbery pi imager
2. Change Username to "dronepi'" and password to "qwe"
3. Change  clock settings(Else internet and things might not work): 
	1. I'm currently using NTP(**Only works when connected to internet**)
	2. Follow [this guide](https://rishabhdevyadav.medium.com/how-to-install-ntp-server-and-client-s-on-ubuntu-18-04-lts-f0562e41d0e1) and use [this pool](https://www.ntppool.org/en/zone/za#:~:text=In%20most%20cases%20it's%20best,closest%20available%20servers%20for%20you.) also set:
```Shell
sudo apt install systemd-timesyncd
timedatectl set-ntp true
```

```Shell
sudo date --set="2015-09-30 10:05:59.990"
sudo timedatectl set-timezone Africa/Johannesburg
sudo apt update
sudo apt install ntp
sudo systemctl start ntp
sudo systemctl enable ntp
sudo systemctl status ntp
```
- confirm that NTP is running. After startup, takes a bit until time is synchronised. Then run "timedatectl" in terminal to ensure time is synchronised
- If you need timxesync when not connected to network, try and use a **Real-Time Clock (RTC) module**
	3. If that doesn't work, try:
```Shell
### 1. Install NTP (if not already installed)

You can install NTP using the following command:

`sudo apt update sudo apt install ntp`

### 2. Enable NTP Service

Once NTP is installed, you need to enable the NTP service to ensure it runs on startup:

`sudo systemctl enable ntp`

### 3. Start NTP Service

Start the NTP service so it starts syncing the time immediately:

`sudo systemctl start ntp`

### 4. Configure NTP (Optional)

The default configuration should work for most users, but if you need to configure NTP to use specific servers, you can edit the configuration file:

`sudo nano /etc/ntp.conf`
###
Add or modify the `server` lines to point to your preferred NTP servers, for example:

Copy code
server 0.africa.pool.ntp.org iburst 
server 1.africa.pool.ntp.org iburst 
server 2.africa.pool.ntp.org iburst 
server 3.africa.pool.ntp.org iburst

Save the file and exit the editor (Ctrl + X, then Y, and Enter).
###
After making changes, save the file and restart the NTP service:

`sudo systemctl restart ntp`

### 5. Verify NTP is Working

You can check if NTP is syncing correctly by running:

`ntpq -p`

This command will display the NTP servers your Raspberry Pi is using and their status.

### 6. Set Timezone (Optional)

Ensure your Raspberry Pi is set to the correct timezone:

`sudo dpkg-reconfigure tzdata`
```

3. connect to internet and run:
```Shell
sudo apt-get update
sudo apt-get upgrade
```

4. To check ubuntu and kernel version, respectively:
```Shell
lsb_release -a
uname -r
```

5. If need to, upgrade the linux kernal using:
```Shell
sudo apt install linux-generic-hwe-22.04
```

## 1.2. Installing Realsense Stuff on Raspberry Pi (also check how to get it working on ubuntu)

1. Clone and compile the latest Intel® RealSense™ SDK 2.0 by following the instructions under [Linux Installation](https://github.com/IntelRealSense/librealsense/blob/development/doc/installation.md). In the section Prerequisites, proceed with the steps till (not including) the kernel patches instructions.
2. DO:
	1. 
https://dev.intelrealsense.com/docs/using-depth-camera-with-raspberry-pi-3
https://github.com/IntelRealSense/librealsense/blob/development/doc/installation.md
https://github.com/cyberRobotic/Intel-Realsense-Ubuntu-Mate
https://dev.intelrealsense.com/docs/ros2-pointcloud-examples

	1. Dont need OpenGL if running RBPi headless
	2. Test if camera works by connecting camera and running ... in terminal
	3. Set time as per Obsidian Records
	4. Install Ros2 as per: https://docs.ros.org/en/humble/Installation/Ubuntu-Install-Debians.html#
		1. Instead of using ~/.bashrc, you have to go to /home/dronepi, "show hidden files" and open the .bashrc file manually. then add the neccessary lines.
            1. source /opt/ros/humble/setup.bash
	5. Test the Ros2 installation using talker-listener
	6. Do: Step 3: Install Intel® RealSense™ ROS2 wrapper from: https://github.com/IntelRealSense/realsense-ros
	7. Launch camera in Ros2 using: 
```Shell
ros2 launch realsense2_camera rs_launch.py depth_module.depth_profile:=1280x720x30 pointcloud.enable:=true
``` 
OR
```Shell
ros2 launch realsense2_camera rs_launch.py depth_module.depth_profile:=640x480x15 pointcloud.enable:=true
``` 
OR
```Shell
ros2 run realsense2_camera realsense2_camera_node --ros-args -p enable_color:=false -p spatial_filter.enable:=true -p temporal_filter.enable:=true
``` 

```Shell
ros2 run realsense2_camera realsense2_camera_node --ros-args -p spatial_filter.enable:=true -p temporal_filter.enable:=true -p rgb_camera.color_profile:=640x480x15 -p enable_rgbd:=True -p depth_module.depth_profile:=640x480x15 -p pointcloud.enable:=True align_depth.enable:=True
``` 

	8. For Streaming ros topics to other pc:
	    1. open.bashrc and add lines:
	        1.1. export ROS_DOMAIN_ID=66
	        1.2. export ROS_LOCALHOST_ONLY=0
	        1.3. Domain ID must eb same for both computers
	        1.4. localhost makes sure ros runs on network and not just locally
	    2. on RBPi run: ros2 launch realsense2_camera rs_launch.py depth_module.depth_profile:=640x480x15 pointcloud.enable:=true
	    3. on other PC run: rviz2 with topics:
	        3.1. Fixed Frame: camera_depth_optical_frame
	        3.2. Depthcloud: /camera/camera/depth/image_rect_raw
	        3.3. Camera: /camera/camera/depth/image_rect_raw


## 1.3. Connecting RBPi to Pixhawk and establish ROS2 connection:
### 1.3.1. Establishing the connection 

1. Follow  [PX4 Raspberry Pi Companion with Pixhawk guide](https://docs.px4.io/main/en/companion_computer/pixhawk_rpi.html) to connect RBPi to pixhawk and establish ROS2 connection
	1. In this guide, use "MAVLink Communication" 
	2. To launch MAVProxy on RBPi 4B, use: If you see something other than "MAV> link 1 down", you have a successful connection
```Shell
sudo mavproxy.py --master=/dev/serial0 --baudrate 57600
```
(This works)



If you want to use uXRCE-DDS, do: 
	1. In this guide, skip "MAVLink Communication" and do "ROS 2 and uXRCE-DDS" instead
	2. Check Status of FC on QGC using:
```Shell
uxrce_dds_client status
```
	3. During Git Setup in "ROS 2 and uXRCE-DDS", also add:
```Shell
sudo apt install git
git config --global user.name "DronePi"
git config --global user.email "2390712@sun.ac.za"
git config --global --list
```
	4. Start uXRCE_DDS agent on RBPi using:
```Shell
sudo MicroXRCEAgent serial --dev /dev/ttyAMA0 -b 921600
```
OR
```Shell
sudo MicroXRCEAgent serial --dev /dev/serial0 -b 921600
```
	5. Now that both agent and client are running, you should see activity on both the MAVLink console and the RPi terminal. You can view the available topics using the following command on the RPi:
```Shell
source /opt/ros/humble/setup.bash
ros2 topic list
```
6. for a successful communication link establishment, you should see lots of topics starting with "/fmu/.........". 
7. **NB!!!** **If you dont see this, check that your "ROS_DOMAIN_ID" in bash.rc onPi and  UXRCE_DDS_DOM_ID parameter on FC are the same (preferably 0). If still not work, also check local host**
8. Check Uorb topics in MAVLink Console on QGC according to [this page](https://docs.px4.io/main/en/middleware/uorb.html) 
	1. List all topics: ls /obj
	2. To check frequency of each topic in real-time use: uorb top
	3. To listen to the content of one topic for 5 messages: listener sensor_accel 5
	4. listener actuator_motors
	5. listener offboard_control_mode

### 1.3.2. Sending/reading topics from FC
1. Check [this page](https://github.com/PX4/PX4-Autopilot/tree/main/msg) for topic names and descriptions
2. TEST: After RBPi has been added, changed following settings (Test of RBPi can arm/disarm drone):
	1. For checking comms between RBPi and FC I chose:
		1. Flight modes:
			1. Altitude mode (No GPS required)
			2. Offboard
			3. Land
		2. Add Arm Switch
		3. Add Emergency kill switch
	2. on QGC MAVLink console check "uxrce_dds_client status"
	3. on Pi open 2 terminals: "sudo MicroXRCEAgent serial --dev /dev/serial0 -b 921600" and "ros2 topic list"
## 1.5. Offboard Control using RBPi

1. Running the Offboard Control Node
	1. Start MicroXRCE Agent
```bash
sudo MicroXRCEAgent serial --dev /dev/serial0 -b 921600
```
	confirm connection using: ros2 topic list

	2. To build the packages(if you did any changes):
```bash
cd ros2_ws_Arming/
colcon build --packages-select offboard_directmotor_control
```
	1. Run the ROS 2 node to control motor outputs:
```bash
ros2 run offboard_directmotor_control motor_control
```
	1. Check if commands pass through on QGC
	2. Arm your UAV using the radio transmitter.
	3. Set radio transmitter into offboard mode(be ready on failsafe/emergency stop) 

### 1.5.1. To create ROS2 node for offboard control, and launch it:
	1. Step 1: Create the ROS 2 Package with the New Name
		1. Navigate to your ROS 2 workspace:
```bash
cd ~/ros2_ws/src
```
		1. Create a new ROS 2 package named `offboard_directmotor_control`:
```bash
ros2 pkg create --build-type ament_python offboard_directmotor_control
```
		1. Go into the `offboard_directmotor_control` package directory:
```bash
cd offboard_directmotor_control
```

	2. Step 2: Writing the Offboard Control Node
		1. Inside the `offboard_directmotor_control` directory, create a Python script for motor control:
```bash
mkdir offboard_directmotor_control
touch offboard_directmotor_control/motor_control.py
chmod +x offboard_directmotor_control/motor_control.py
```
		
		2. Edit `motor_control.py` to publish motor control commands. Use pluma text editor to add the "motor control code":
		    

	3. Step 3: Update Package Configuration
		1. Open `setup.py` in the `offboard_directmotor_control` directory and modify the `entry_points` section:
```python
entry_points={
	'console_scripts': [
		'motor_control = offboard_directmotor_control.motor_control:main',
	],
},
```

		2. Update `package.xml` to declare dependencies:
```xml
<depend>rclpy</depend>
<depend>px4_msgs</depend>
```

	4. Step 4: Building the Package
		1. Navigate to the root of your ROS 2 workspace:
```bash
cd ~/ros2_ws
```
		2. Build the workspace:
```bash
colcon build
```
		3. Source the workspace in .bashrc:
```bash
source /home/dronepi/ros2_ws_Arming/install/setup.bash
```

	5. Step 5: Running the Offboard Control Node
		1. Arm your UAV using the radio transmitter.
	    Start MicroXRCE Agent
```bash
sudo MicroXRCEAgent serial --dev /dev/serial0 -b 921600
```
	    confirm connection using: ros2 topic list

		2. To build the packages(if you did any changes):
```bash
cd ros2_ws_Arming/
colcon build --packages-select offboard_directmotor_control
```
		3. Run the ROS 2 node to control motor outputs:
```bash
ros2 run offboard_directmotor_control motor_control
```
		4. Check if commands pass through on QGC
		5. Set radio transmitter into offboard mode(be ready on failsafe/emergency stop) 

### 1.5.2.  Basic offboard without position, velocity or acceleration data

1. Launch Sudo MicroXRCEAgent
	1. Check if launched using ros2 topic list
2. Launch Offboard direct motor control
3. Make sure QGC parameter:
	1. `COM_ARM_WO_GPS` is set to `Allow arming without GPS`
	2. `EKF2_HGT_REF` to `Barometer pressure`
4. Offboard control mode with dynamic velocity changing:
	1. Run: pip3 install pynput
5. Dont think can directly change motor speed when no position estimate is available. What I did for now was to just set uav into offboard mode and send arming command in 0.1s intervals. Can be seen that uav arms, after 10s, failsafe triggers, as no takeoff detected, so uav disarms, within 0.1s, motors get rearmed by command. 
	1. NOTE!!!: Arming also works in all other modes, so handle with care


### 1.5.3. Offboard control with IMU and Optical Flow Camera
	1. Some things to consider when [adding optical flow sensor](https://discuss.px4.io/t/drone-gets-disarmed-automatically-in-offboard-mode/21127) 
	2. To Prevent Auto-Disarming, check [this page](https://docs.px4.io/main/en/advanced_config/prearm_arm_disarm.html) 
	3. Code for getting position control from Optical Flow is available in a repo mentioned in [This video](https://www.youtube.com/watch?v=u0ufRLX_sZI&ab_channel=DennisBaldwin) 
7. Offboard control doing  the following [from Jaeyoung-Lim](https://github.com/Jaeyoung-Lim/px4-offboard) :
	1. `offboard_control.py`: Example of offboard position control using position setpoints
	2. `visualizer.py`: Used for visualizing vehicle states in Rviz

### 1.5.4. (MAVLink or uxrce???????)Follow [this page](https://docs.px4.io/main/en/ros2/offboard_control.html) to test drone in offboard mode. The programme starts sending setpoints, enters offboard mode, arms, ascends to 5 metres, and waits
		1. NOTE: 
			1. Do this on test rig
			2. Reduce to 50cm?
			3. Make sure to have a failsafe/way of gaining back manual control in case something goes wrong
		2. NOTE:  px4_msgs already installed and built 


### 1.5.5. Running QGC on Pi for Auto-Tuning

1. Use standard Ubuntu installation. Did not work
2. Try mengchaoheng method from [here](https://github.com/mavlink/qgroundcontrol/issues/9856) : Installs QGC, but does not seem to be working

## 1.6. Running Raspberry Pi Headlessly (VNC vs SSH)
1. Raspberry Pi Headless
	1. [vnc](file:///home/nico/Downloads/headless_setup_with_ubuntu_mate.pdf) - check on private network (can see whole screen)
	2. [ssh installations steps](https://hostman.com/tutorials/how-to-install-and-configure-ssh-on-ubuntu-22-04/) (test again on uni network, but works on private network. Only terminal, no UIs)
		1. You can open multiple terminals, but have to run "ssh dronepi@172.20.10.4" or "ssh username@IP_address" in each one
		2. Once done, type "exit" in the open ssh terminal to close the session
		3. In final terminal, type "sudo poweroff" to turn off Pi








# 2. Ubuntu PC
## Getting The RGBD Camera to work (Works for PC; For RBPi use other method)
1. Follow steps on [this website](https://github.com/IntelRealSense/realsense-ros/tree/ros2-development). Follow the following:
	1. Step 1 : ROS2 Humble
	2. Step 2: Option 1: Install librealsense2 debian package from Intel servers (Option2 for Vim4)
		1. Otherwise, install from [Linux Debian Installation Guide](https://github.com/IntelRealSense/librealsense/blob/master/doc/distribution_linux.md#installing-the-packages)
	4. Step 3: Option 1: Install debian package from ROS servers (Option for Vim4)
				OR Option2: install from source
1. Test the camera using the following command:
```Shell
realsense-viewer
```
3. Starting a ROS2 camera node:
```Shell
ros2 launch realsense2_camera rs_launch.py
ros2 launch realsense2_camera rs_launch.py depth_module.depth_profile:=1280x720x30 pointcloud.enable:=true
```

4. To record a Rosbag:
	1. Open a terminal and directory where rosbag should be saved and run the following code
```Shell
cd
cd Rosbagrec
ros2 bag record -o filename1 --all
```

5. To replay rosbag:
	1. Open Terminal with RVIZ
	2. Open Specific RVIZ config file
	3. Replay the specific rosbag using the following prompt:

```Shell
cd
cd Rosbagrec
ros2 bag play rosbag2_2024_08_07-13_51_12/
```






# 3. Ubuntu Khadas Vim4 
## 3.1. Setting up Khadas Vim4 (in-depth)

Others to consider with intelx64 processors:
1. UP Squared
2. LattePanda 3 Delta 864
3. SBC-pITX-EHL X6425E

[GPIO Pinout](https://habr.com/ru/companies/selectel/articles/679282/) can be found here and can be seen below. In Picture below, the pins are alligned, where the 3.3V pin is the one closest to the HDMI Input(Type-D)

![[Screenshot from 2024-11-08 19-58-56.png]]
will use pin 15,16,17 to connect to FC


Setting up the Khadas Vim4:
1. Start OOWOW by holding "holding function and pushing reset buttons"
2. Connect to a network
3. Install ubuntu 22.04 GNOME using OOWOW, by holding "Function" and pressing "Reset" buttons. Images can be found [here](https://docs.khadas.com/products/sbc/vim4/os-images/start) 
4. Password will be "khadas"
5. Update and upgrade the system
	1. If asked for Display drivers or something like that, push esc. Previously didn't work when selecting one
6. Change  clock settings(Else internet and things might not work): 
	1. I'm currently using NTP(**Only works when connected to internet**)
```Shell
sudo date --set="2015-09-30 10:05:59.990"
sudo timedatectl set-timezone Africa/Johannesburg
sudo apt update
sudo apt install ntp
sudo systemctl start ntp
sudo systemctl enable ntp
sudo systemctl start ntp
sudo systemctl status ntp
```
- confirm that NTP is running. After startup, takes a bit until time is synchronised. Then run "timedatectl" in terminal to ensure time is synchronised
- If you need timesync when not connected to network, try and use a **Real-Time Clock (RTC) module**
7. [Install Chromium and (if you need WebGL)](https://docs.khadas.com/products/sbc/vim4/applications/chromium) 
8. Install Firefox (Didn't work anymore last time I tried):
```Shell
sudo apt install snap
sudo snap install firefox
sudo apt install chromium-browser
```
9. Install ROS2 Humble Hawksbilll from [this website](https://docs.ros.org/en/humble/Installation/Ubuntu-Install-Debians.html) 


### ROS2 (Humble)
```bash
locale  # check for UTF-8

sudo apt update && sudo apt install locales
sudo locale-gen en_US en_US.UTF-8
sudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8
export LANG=en_US.UTF-8

locale  # verify settings

sudo apt install software-properties-common
sudo add-apt-repository universe

sudo apt update && sudo apt install curl -y
sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg

echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release && echo $UBUNTU_CODENAME) main" | sudo tee /etc/apt/sources.list.d/ros2.list > /dev/null

sudo apt update
sudo apt upgrade
```

```bash
sudo apt install ros-humble-desktop

sudo apt install ros-humble-ros-base

sudo apt install ros-dev-tools

#sudo apt install python3-colcon-common-extensions
```

```bash
gedit ~/.bashrc
```
add the following to the end of the `~/.bashrc` script:
```bash
source /opt/ros/humble/setup.bash
source /usr/share/colcon_argcomplete/hook/colcon-argcomplete.bash
export ROS_DOMAIN_ID=0
export ROS_LOCALHOST_ONLY=1
```
[[ROS2 commands]] 

### Test ROS2 Installation:
1. In terminal 1 run:
```bash
ros2 run demo_nodes_cpp talker
```

2. In terminal 2 run:
```bash
ros2 run demo_nodes_py listener
```

### Connecting Vim4 to FC

8. Use serial port setup, which can be found [here](https://docs.px4.io/main/en/companion_computer/pixhawk_companion.html) or direct to jumpers like it was done with the [RaspsberryPi](https://docs.px4.io/main/en/companion_computer/pixhawk_rpi.html)
		1. Might  need USB to Serial breakout board:
			- https://www.robotics.org.za/W6170?search=ftdi%20usb%20to%20serial
			- https://www.mantech.co.za/ProductInfo.aspx?Item=15M0301 needs soldering
		2. OR: Connect directly to companion
	1. Decide to use either MAVLink or  uXRCE-DDS between companion and Flight controller (First thought = MAVLink: Seems simpler to implement)
	2. PX4 expects companion computers to connect via TELEM2 for offboard control. The port is configured by default to interface using MAVLink
	3. To use [ROS 2/uXRCE-DDS](https://docs.px4.io/main/en/ros/ros2_comm.html) instead of MAVLink on `TELEM2`, disable MAVLink on the port and then enable the uXRCE-DDS client on `TELEM2`

Check out [this computer vision link](https://docs.px4.io/main/en/computer_vision/)
## 3.2. Setting up Khadas Vim4 (All you need)

Works on image:"-------------------------------------------------------------h"

### 3.2.1. ROS2 (Humble) installation

1. 
```Shell
locale  # check for UTF-8
sudo apt update && sudo apt install locales
sudo locale-gen en_US en_US.UTF-8
sudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8
export LANG=en_US.UTF-8
locale  # verify settings
sudo apt install software-properties-common
sudo add-apt-repository universe
sudo apt update && sudo apt install curl -y
sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release && echo $UBUNTU_CODENAME) main" | sudo tee /etc/apt/sources.list.d/ros2.list > /dev/null
sudo apt update
sudo apt upgrade
```

2. 
```Shell
sudo apt install ros-humble-desktop
sudo apt install ros-humble-ros-base
sudo apt install ros-dev-tools
sudo apt install python3-colcon-common-extensions
```

3. 
```Shell
gedit ~/.bashrc
```

4. 
add the following to the end of the `~/.bashrc` script:
```Shell
source /opt/ros/humble/setup.bash
source /usr/share/colcon_argcomplete/hook/colcon-argcomplete.bash
export ROS_DOMAIN_ID=0
export ROS_LOCALHOST_ONLY=0
```

### 3.2.2.  Test ROS2 Installation:
1.  In terminal 1 run:
```Shell
ros2 run demo_nodes_cpp talker
```

2. In terminal 2 run:
```Shell
ros2 run demo_nodes_py listener
```

### 3.2.3. Test if RVIZ2 is running. 
1. Previously didnt work. Dont really need it, but is nice for verifying data. 
2. Problem:It seems like there is some issue with how wayland and qt are packaged. You can set the platform to use x11 instead by setting the `QT_QPA_PLATFORM` environmental variable to `xcb`
3. Solution 1: 
	1. In terminal, run (Actually, I think you might have to add it to gedit ~/.bashrc):
```Shell
export QT_QPA_PLATFORM=xcb
```
	Then launch rviz using "rviz2"
4. Solution 2: Can run RVIZ over network though using ros2 and visulaize on other pc

### 3.2.4. Getting OAK-D Pro W to work

1. After ROS2 humble installation, run:
```Shell
sudo apt install ros-humble-depthai-ros
sudo wget -qO- https://docs.luxonis.com/install_dependencies.sh | bash
echo 'SUBSYSTEM=="usb", ATTRS{idVendor}=="03e7", MODE="0666"' | sudo tee /etc/udev/rules.d/80-movidius.rules
sudo udevadm control --reload-rules && sudo udevadm trigger
```

2. 
```Shell
sudo python3 -m pip install depthai
sudo python3 -m pip install depthai-viewer
sudo apt install python3.10-venv
```

3. For testing successful installation (Does not work, go to step 4 for testing):
```Shell
python3 -m depthai_viewer
```

4. For launching in ROS2 do as follows or similar:
```Shell
ros2 launch depthai_examples stereo_inertial_node.launch.py
```


### 3.2.5. Installing PX4 (Enables reading of FC Topics)

#### 3.2.5.1. Create ros2 workspace and build PX4_msgs

1. Creating workspace
```Shell
cd
mkdir ros2_ws
cd ros2_ws
mkdir src
source ~/ros2_ws/install/setup.bash
sudo rosdep init
rosdep update 
```

2. Clone PX4 msgs and build workspace
```Shell
cd 
cd ros2_ws/src/
git clone https://github.com/PX4/px4_msgs.git
cd ~/ros2_ws
rosdep update
rosdep install --from-paths src --ignore-src -r -y
colcon build
```
OR use colcon build --packages-select px4_msgs

3.  Add ros2 workspace to .bashrc file
```Shell
gedit ~/.bashrc
```
and add
```Shell
source /home/khadas/ros2_ws/install/setup.bash
```

#### 3.2.5.1. Create offboard control node

TODO:
1. Look at Section 1.5. of this file to see how to add offboard control node



### 3.2.6.  Connect Vim4 to FC

Follows the instructions available [here](https://docs.px4.io/main/en/companion_computer/pixhawk_rpi.html) 

1. Enable UART on Khadas VIM4: The VIM4's UART_E interface is available on GPIO pins 15 (RX) and 16 (TX). 
	1. To enable this UART do:
```Shell
sudo nano /boot/dtb/amlogic/kvim4n.dtb.overlay.env
```
	 2. Add the following text: fdt_overlays=uart_e
	 3. Reboot
	 4. After restart, do: 
```Shell
ls /dev/
```
	5. you should see /dev/ttyS4

2. Install git using the RPi terminal:
```Shell
sudo apt install git
git config --global user.name "DroneVIM"
git config --global user.email "2390712@sun.ac.za"
git config --global --list
```

3. Install the uXRCE_DDS agent:
```Shell
git clone https://github.com/eProsima/Micro-XRCE-DDS-Agent.git
cd Micro-XRCE-DDS-Agent
mkdir build
cd build
cmake ..
make
sudo make install
sudo ldconfig /usr/local/lib/
```

4. Connect pins 15,16 and 17 to FCs TELEM tx, rx, gnd

5. start the agent in the RPi terminal:
```
sudo MicroXRCEAgent serial --dev /dev/ttyS4 -b 921600
```

6. confirm that connection is established
```Shell
ros2 topic list 
```

7. Troubleshooting (If you dont see topics like /fmu/in/sensor_optical_flow)
	1. On QGC, in mavlink console, run: uxrce_dds_client status 
		1. Make sure connection is ona nd running
	2. Make sure in ~/.bashrc, ROS_LOCALHOST_ONLY is set to 0 and ROS_DOMAIN_ID is also 0(has to be same as UXRCE_DDS_DOM_ID parameter in QGC)
### 3.2.7.  Set up Headless mode
1. On Vim4(server) as well as on other pc(client) from [here](https://hostman.com/tutorials/how-to-install-and-configure-ssh-on-ubuntu-22-04/) :
```Shell
sudo apt update && sudo apt upgrade
sudo apt install openssh-server
sudo systemctl enable --now ssh
```

2. To check if the SSH is running:
```Shell
sudo systemctl status ssh
```

3. Configuring Firewall (check status and allow ssh connection), if ufw is installed:
```Shell
sudo ufw status
```

```Shell
sudo ufw allow ssh
```

3. To connect to SSH Server: 
	1. Make sure you are on the same network
	2. in terminal, type (Note: can have multiple terminals open at once):
```Shell
ssh username@IP_address
```
e.g.
```Shell
ssh khadas@192.168.137.170
```
	1. To close ssh connection, type "exit" in terminal, to turn off Server, type "sudo poweroff" in terminal

4. To turn off SSH:
```Shell
sudo systemctl disable ssh
```



### 3.2.15. Other interesting but non-critical things

#### 3.2.15.1. Checking CPU usage:

1. htop shows usage of each core, ram and swap: 
```Shell
sudo apt install htop
```

```Shell
htop
```

2. Glances shows cpu usage and temperature:
```Shell
sudo apt install glances
```

```Shell
glances
```

#### 3.2.15.2. Increasing SWAP space (increase ram)
1. From [Here](https://www.digitalocean.com/community/tutorials/how-to-add-swap-space-on-ubuntu-20-04) :The swap space on the hard drive will be used mainly when there is no longer sufficient space in RAM to hold in-use application data. The information written to disk will be significantly slower than information kept in RAM, but the operating system will prefer to keep running application data in memory and use swap for the older data
2. Follow [these instructions](https://linux.how2shout.com/how-to-increase-swap-space-in-ubuntu-22-04-lts-jammy/) if you want to increase swap space

#### 3.2.15.3. Using SD Card for storage (OS on emmc using OWOOW)
1. Simply format SD card to Fat32/Fat format and insert into slot

#### 3.2.15.4. Disable Bluetooth on Start-Up

Do this, as we want to disconnect antenna. Apparently when module runs and antenna connected, some impedence problem and module heats up. look into that. This guide is taken from [here](https://www.tecmint.com/disable-bluetooth-linux/) 
1. To Stop bluetooth services from starting automatically on system boot, do:
```Shell
sudo systemctl disable bluetooth.service
```

	 To check, restart the Linux system and see if Bluetooth launches on its own during startup.
```Shell
systemctl list-units | grep bluetooth
systemctl status bluetooth.service
```

2. To ensure that the Bluetooth modules don’t load during the system startup, open and edit the ** sudo nano /etc/modprobe.d/blacklist.conf** file using your favorite text editor and add the following lines at the end of the file.
```Shell
blacklist bluetooth
blacklist btusb
```

3. To enable bluetooth services again: Revert Step 2 (**/etc/modprobe.d/blacklist.conf**) and run following in terminal:
```Shell
sudo systemctl enable bluetooth.service
sudo systemctl start bluetooth.service
sudo systemctl status bluetooth.service
```


### 3.2.16. Things that don't work yet
1. Intel Realsense stuff. Try [this](https://forum.khadas.com/t/anyone-have-luck-building-the-intel-realsense-sdk-2-0/17652) 






# 4. Stuff I tried that doesn't work
##  XXXXX Intel Realsense D35i RGBD on VIM4 ChatGPT(Does Not Work)

Yes, it's possible to run an Intel RealSense D435i camera on ROS2 on a Khadas VIM4 with ARM64 architecture and a USB 3.0 port. Here's a general guide on how to set this up:

### 1. **Install ROS2 on Khadas VIM4**
   - **Ubuntu Setup**: Ensure your Khadas VIM4 is running Ubuntu. You can use a 20.04 or 22.04 version since ROS2 Foxy and Humble are commonly used versions.
   - **Install ROS2**: Follow the ROS2 installation guide for ARM64 architecture [here](https://docs.ros.org/en/foxy/Installation/Ubuntu-Install-Debians.html) or [here](https://docs.ros.org/en/humble/Installation/Ubuntu-Install-Debians.html) depending on your ROS2 version preference.
   - **Change clock settings**:  Else internet and things might not work:
```Shell
sudo date --set="2015-09-30 10:05:59.990"
sudo hwclock --systohc
```

### 2. **Install Intel RealSense SDK**
   - **Install the SDK**: The RealSense SDK (librealsense) needs to be installed and configured for ARM64 architecture. Intel provides precompiled binaries for x86, but for ARM, you'll need to build it from source.
     1. **Dependencies**: Install required dependencies:
        ```bash
        sudo apt-get install git cmake build-essential libssl-dev libusb-1.0-0-dev pkg-config libgtk-3-dev
        ```
     2. **Clone and Build librealsense**:
        ```bash
        git clone https://github.com/IntelRealSense/librealsense.git
        cd librealsense
        mkdir build && cd build
        cmake .. -DFORCE_LIBUVC=true -DCMAKE_BUILD_TYPE=Release
        make -j4
        sudo make install
        ```

### 3. **Install ROS2 RealSense Package**
   - **Install ROS2 Wrapper**: Use the RealSense ROS2 wrapper, which integrates the camera with ROS2.
     1. **Clone the ROS2 Wrapper**:
        ```bash
        cd ~/ros2_ws/src
        git clone https://github.com/IntelRealSense/realsense-ros.git
        cd ~/ros2_ws
        colcon build --symlink-install
        ```
     2. **Environment Setup**:
        ```bash
        source ~/ros2_ws/install/setup.bash
        ```

### 4. **Connect the RealSense Camera**
   - Plug the Intel RealSense D435i into the USB 3.0 port of the Khadas VIM4.
   - Verify that the camera is detected:
     ```bash
     realsense-viewer
     ```

### 5. **Run the ROS2 Node**
   - Launch the ROS2 RealSense node:
     ```bash
     ros2 launch realsense2_camera rs_launch.py
     ```

### 6. **Troubleshooting**
   - Ensure you have the correct udev rules for the camera.
   - Monitor `dmesg` for any USB issues.
   - Adjust performance settings on the VIM4 to ensure adequate resources are allocated.

### Additional Tips:
   - Consider using a fan or heatsink on the VIM4 if the system runs hot during operation.
   - If you encounter issues, you might need to tweak the kernel or USB settings due to the ARM architecture.

This setup should enable you to run the Intel RealSense D435i camera with ROS2 on your Khadas VIM4.
## XXXXX Setting up Rock Pi 5B (This thing is a bit useless)

1. Installing Ubuntu. Choose between [GNOME vs Xfce vs KDE](https://www.vpsserver.com/gnome-vs-xfce-vs-kde/#:~:text=Xfce%20is%20faster%20than%20KDE,quicker%20desktop%20environment%20than%20GNOME.) (Mate is not available:)
	1. Download image from [here](https://github.com/radxa-build/rock-5b/releases/tag/b39), flash to SD card and run on Rock Pi
	2. Or download from [official site](https://wiki.radxa.com/Rock5/downloads) or from [here](https://joshua-riek.github.io/ubuntu-rockchip-download/boards/rock-5b.html) 
	3. [here](https://github.com/Qengineering/Rock-5-Ubuntu-22-image) and [here](https://www.reddit.com/r/SBCs/comments/1820xr0/ubuntu_for_rock_5b/) 
	4. 
2. Use Raspberry Pi imager for flashing image somehow BalenaEtcher doesn't work






